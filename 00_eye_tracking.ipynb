{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python (deep_learn)","language":"python","name":"deep_learn"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"name":"00_eye_tracking.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"25833777"},"source":["# Making CSV From Videos"],"id":"25833777"},{"cell_type":"code","metadata":{"id":"4fd0fd5a"},"source":["# All Imports\n","import cv2\n","import os\n","import mediapipe as mp\n","import time\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"],"id":"4fd0fd5a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"tags":[],"id":"e1556413"},"source":["# Making CSV from landmark points\n","empty_list_big = []\n","empty_list_small = []\n","name_of_lists = []\n","for i in range(1,469):\n","    name_of_lists.append(str(i)+'x')\n","    name_of_lists.append(str(i)+'y')\n","\n","\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","out = cv2.VideoWriter('output.mp4', fourcc, 15.0, (640, 480))\n","\n","#cap = cv2.VideoCapture(\"up.avi\")\n","cap = cv2.VideoCapture(0)\n","pTime = 0\n","\n","mpDraw = mp.solutions.drawing_utils\n","mpFaceMesh = mp.solutions.face_mesh\n","faceMesh = mpFaceMesh.FaceMesh(max_num_faces=1)\n","drawSpec = mpDraw.DrawingSpec(thickness=1, circle_radius=2)\n","\n","while True:\n","    success, img = cap.read()\n","    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    results = faceMesh.process(imgRGB)\n","    if results.multi_face_landmarks:\n","        for faceLms in results.multi_face_landmarks:\n","            mpDraw.draw_landmarks(img, faceLms, mpFaceMesh.FACE_CONNECTIONS,\n","                                  drawSpec,drawSpec)\n","            for id,lm in enumerate(faceLms.landmark):\n","                #print(lm)\n","                ih, iw, ic = img.shape\n","                x,y = int(lm.x*iw), int(lm.y*ih)\n","                #print(id+1,x,y)\n","                #empty_list_small.append(id+1)\n","                empty_list_small.append(x)\n","                empty_list_small.append(y)\n","            empty_list_big.append(empty_list_small)\n","            empty_list_small = []\n","\n","    cTime = time.time()\n","    fps = 1 / (cTime - pTime)\n","    pTime = cTime\n","    cv2.putText(img, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_PLAIN,\n","                3, (255, 0, 0), 3)\n","    cv2.imshow(\"Image\", img)\n","    out.write(img)\n","    if cv2.waitKey(1) == 13:\n","        break\n","\n","df = pd.DataFrame(empty_list_big, columns = name_of_lists)\n","df.to_csv(\"all_landmarks.csv\", index= False)\n","\n","cap.release()\n","cv2.destroyAllWindows()"],"id":"e1556413","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f1861275"},"source":[""],"id":"f1861275","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e0c98ac0"},"source":[""],"id":"e0c98ac0","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fbb2dd7a"},"source":["# Capturing Image Frames For Dataset"],"id":"fbb2dd7a"},{"cell_type":"code","metadata":{"id":"b0826c07"},"source":["# Video capturing and dataset making \n","# We will capture 2000 frames per classes\n","# The outputs classes are Up, Down, Left, Right, Upper Left, Upper Right, Lower Left, Lower Right, and Middle or Neutral \n","# There should be a video that consits of all the classes for the experimental purposes "],"id":"b0826c07","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"c213f0f1"},"source":["# Changeable Parameters\n","image_name = 'all_case'\n","max_count = 1000\n","\n","\n","#img = cv2.imread('1.jpg', 1)\n","#path = 'D:/OpenCV/Scripts/Images'\n","path = 'dataset/images/'\n","path = os.path.join(path, image_name)\n","\n","if not os.path.isdir(path):\n","    os.mkdir(path)\n","\n","\n","#fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","#out = cv2.VideoWriter(file_name, fourcc, 20.0, (640, 480))\n","\n","#cap = cv2.VideoCapture(\"Videos/1.mp4\")\n","cap = cv2.VideoCapture(0)\n","\n","count = 0\n","while True:\n","    \n","    success, img = cap.read()\n","    \n","    count += 1\n","    \n","    cv2.imwrite(os.path.join(path, image_name + str(count)+'.jpg'), img)\n","    #out.write(img)\n","    #print(img.shape)\n","    if count%100 == 0:\n","        print(count)\n","    cv2.imshow(\"Image\", img)\n","    if cv2.waitKey(1) == 13:\n","        break\n","    elif count == max_count:\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()"],"id":"c213f0f1","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5a102e95"},"source":["# Making CSV Files from the images"],"id":"5a102e95"},{"cell_type":"code","metadata":{"tags":[],"id":"ba713022"},"source":["def csv_maker(image_name):\n","    # Reading Folderwide all images\n","    #image_name = 'all_case'\n","    # Making CSV from landmark points\n","    empty_list_big = []\n","    empty_list_small = []\n","    name_of_lists = []\n","    \n","    for i in range(468):\n","        name_of_lists.append(str(i)+'x')\n","        name_of_lists.append(str(i)+'y')\n","\n","    path = 'dataset/images/'\n","    path = os.path.join(path, image_name)\n","    images = os.listdir(path)\n","\n","    mpDraw = mp.solutions.drawing_utils\n","    mpFaceMesh = mp.solutions.face_mesh\n","    faceMesh = mpFaceMesh.FaceMesh(max_num_faces=1)\n","    drawSpec = mpDraw.DrawingSpec(thickness=1, circle_radius=2)\n","\n","    for every_image in images:\n","        img = cv2.imread(path+'/' + every_image)\n","        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        results = faceMesh.process(imgRGB)\n","        if results.multi_face_landmarks:\n","            for faceLms in results.multi_face_landmarks:\n","                mpDraw.draw_landmarks(img, faceLms, mpFaceMesh.FACE_CONNECTIONS,\n","                                      drawSpec,drawSpec)\n","                for id,lm in enumerate(faceLms.landmark):\n","                    #print(lm)\n","                    ih, iw, ic = img.shape\n","                    x,y = int(lm.x*iw), int(lm.y*ih)\n","                    #print(id+1,x,y)\n","                    #empty_list_small.append(id+1)\n","                    empty_list_small.append(x)\n","                    empty_list_small.append(y)\n","                empty_list_big.append(empty_list_small)\n","                empty_list_small = []\n","\n","\n","    df = pd.DataFrame(empty_list_big, columns = name_of_lists)\n","    df[\"output\"] = image_name\n","    df.to_csv(\"dataset/csv/\"+ image_name+\".csv\", index = False)\n","\n","\n","    \n","    return str(image_name) + \"done\"\n","    \n","\n"],"id":"ba713022","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"d5cae41c"},"source":["class_list = [\"down\", \"left\", \"lower_left\", \"lower_right\",\"middle\", \"right\", \"up\",\"upper_left\", \"upper_right\"]\n","for every_class in class_list:\n","    print(csv_maker(every_class))\n","    "],"id":"d5cae41c","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"70d2107a-e8bf-4ba6-906b-51174bd6c788"},"source":["# Eye Bounding box applied to realtime video"],"id":"70d2107a-e8bf-4ba6-906b-51174bd6c788"},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"tags":[],"id":"c936d952-c188-4bfe-9448-0090ad17f271"},"source":["# Eye Bounding box applied to realtime video\n","# Parameters for eye landmark\n","# Landmark id starts from 0 ..please remember that \n","r1 = 285 #336 # 285\n","r2 = 261 #340 # 261\n","\n","l1 = 55 #70\n","l2 = 31 #196\n","\n","empty_list_big = []\n","empty_list_small = []\n","name_of_lists = []\n","\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","out = cv2.VideoWriter('output.mp4', fourcc, 15.0, (640, 480))\n","\n","#cap = cv2.VideoCapture(\"up.avi\")\n","cap = cv2.VideoCapture(0)\n","pTime = 0\n","\n","mpDraw = mp.solutions.drawing_utils\n","mpFaceMesh = mp.solutions.face_mesh\n","faceMesh = mpFaceMesh.FaceMesh(max_num_faces=1)\n","drawSpec = mpDraw.DrawingSpec(thickness=1, circle_radius=0)\n","\n","while True:\n","    success, img = cap.read()\n","    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    results = faceMesh.process(imgRGB)\n","    if results.multi_face_landmarks:\n","        for faceLms in results.multi_face_landmarks:\n","            #mpDraw.draw_landmarks(img, faceLms, mpFaceMesh.FACE_CONNECTIONS,\n","            #                      drawSpec,drawSpec)\n","            for id,lm in enumerate(faceLms.landmark):\n","                #print(lm)\n","                ih, iw, ic = img.shape\n","                x,y = int(lm.x*iw), int(lm.y*ih)\n","                #print(id+1,x,y)\n","                #empty_list_small.append(id+1)\n","                empty_list_small.append(x)\n","                empty_list_small.append(y)\n","            empty_list_big.append(empty_list_small)\n","            right_eye_x1 = empty_list_small[2 * r1] \n","            right_eye_y1 = empty_list_small[2 * r1 + 1] \n","            right_eye_x2 = empty_list_small[2 * r2 ] \n","            right_eye_y2 = empty_list_small[2 * r2 + 1] \n","            \n","            left_eye_x1_not = empty_list_small[2 * l1] \n","            left_eye_y1_not = empty_list_small[2 * l1 + 1] \n","            left_eye_x2_not = empty_list_small[2 * l2 ] \n","            left_eye_y2_not = empty_list_small[2 * l2 + 1]  \n","            \n","            left_eye_x1 = left_eye_x2_not\n","            left_eye_y1 = left_eye_y1_not\n","            left_eye_x2 = left_eye_x1_not\n","            left_eye_y2 = left_eye_y2_not\n","            \n","            #print((right_eye_x1,right_eye_y1),(right_eye_x2,right_eye_y2))\n","            cv2.rectangle(img,(right_eye_x1,right_eye_y1),(right_eye_x2,right_eye_y2),(0,255,0),2)\n","            cv2.rectangle(img,(left_eye_x1,left_eye_y1),(left_eye_x2,left_eye_y2),(0,255,0),2)\n","            empty_list_small = []\n","\n","    cTime = time.time()\n","    fps = 1 / (cTime - pTime)\n","    pTime = cTime\n","    cv2.putText(img, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_PLAIN,\n","                3, (255, 0, 0), 3)\n","    cv2.imshow(\"Image\", img)\n","    out.write(img)\n","    if cv2.waitKey(1) == 13:\n","        break\n","\n","#df = pd.DataFrame(empty_list_big, columns = name_of_lists)\n","#df.to_csv(\"all_landmarks.csv\", index= False)\n","\n","cap.release()\n","cv2.destroyAllWindows()"],"id":"c936d952-c188-4bfe-9448-0090ad17f271","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"68797cf5"},"source":["# Image Cropping and Making a seperate dataset"],"id":"68797cf5"},{"cell_type":"code","metadata":{"tags":[],"id":"79b78ebc"},"source":["def eye_crop(img):\n","    # Parameters for eye landmark\n","    # Landmark id starts from 0 ..please remember that \n","    r1 = 285 #336 # 285\n","    r2 = 261 #340 # 261\n","\n","    l1 = 55 #70\n","    l2 = 31 #196\n","\n","    empty_list_big = []\n","    empty_list_small = []\n","    name_of_lists = []\n","\n","    mpDraw = mp.solutions.drawing_utils\n","    mpFaceMesh = mp.solutions.face_mesh\n","    faceMesh = mpFaceMesh.FaceMesh(max_num_faces=1)\n","    drawSpec = mpDraw.DrawingSpec(thickness=1, circle_radius=0)\n","\n","    #success, img = cap.read()\n","    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    results = faceMesh.process(imgRGB)\n","    if results.multi_face_landmarks:\n","        for faceLms in results.multi_face_landmarks:\n","            #mpDraw.draw_landmarks(img, faceLms, mpFaceMesh.FACE_CONNECTIONS,\n","            #                      drawSpec,drawSpec)\n","            for id,lm in enumerate(faceLms.landmark):\n","                #print(lm)\n","                ih, iw, ic = img.shape\n","                x,y = int(lm.x*iw), int(lm.y*ih)\n","                #print(id+1,x,y)\n","                #empty_list_small.append(id+1)\n","                empty_list_small.append(x)\n","                empty_list_small.append(y)\n","            empty_list_big.append(empty_list_small)\n","            right_eye_x1 = empty_list_small[2 * r1] \n","            right_eye_y1 = empty_list_small[2 * r1 + 1] \n","            right_eye_x2 = empty_list_small[2 * r2 ] \n","            right_eye_y2 = empty_list_small[2 * r2 + 1] \n","            \n","            left_eye_x1_not = empty_list_small[2 * l1] \n","            left_eye_y1_not = empty_list_small[2 * l1 + 1] \n","            left_eye_x2_not = empty_list_small[2 * l2 ] \n","            left_eye_y2_not = empty_list_small[2 * l2 + 1]  \n","            \n","            left_eye_x1 = left_eye_x2_not\n","            left_eye_y1 = left_eye_y1_not\n","            left_eye_x2 = left_eye_x1_not\n","            left_eye_y2 = left_eye_y2_not\n","            \n","            img_left = img[left_eye_y1:left_eye_y2, left_eye_x1:left_eye_x2]\n","            img_right = img[right_eye_y1:right_eye_y2, right_eye_x1:right_eye_x2]\n","            \n","            #cv2.rectangle(img,(right_eye_x1,right_eye_y1),(right_eye_x2,right_eye_y2),(0,255,0),2)\n","            #cv2.rectangle(img,(left_eye_x1,left_eye_y1),(left_eye_x2,left_eye_y2),(0,255,0),2)\n","            empty_list_small = []\n","            \n","            return img_left, img_right\n","\n"],"id":"79b78ebc","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4d55cd69"},"source":["def image_saver(image_name):\n","    \n","    \n","    \n","    base_dir = 'dataset/eye_cropped'\n","    training_path = os.path.join(base_dir, 'training')\n","    validation_path = os.path.join(base_dir, 'validation')\n","    \n","    if not os.path.isdir(os.path.join(training_path, image_name)):\n","        os.mkdir(os.path.join(training_path, image_name))\n","    if not os.path.isdir(os.path.join(validation_path, image_name)):\n","        os.mkdir(os.path.join(validation_path, image_name))\n","    \n","    input_image_path = 'dataset/images/'\n","    input_image_path = os.path.join(input_image_path, image_name)\n","    images = os.listdir(input_image_path)\n","\n","    count = 1\n","    for every_image in images:\n","        img = cv2.imread(input_image_path + '/' + every_image)\n","        img_left, img_right = eye_crop(img)\n","        if count <= 800:\n","            cv2.imwrite(os.path.join(training_path, image_name + '/' + 'eye_left' + every_image ), img_left)\n","            cv2.imwrite(os.path.join(training_path, image_name + '/' +  'eye_right' + every_image), img_right)\n","        else:\n","            cv2.imwrite(os.path.join(validation_path, image_name + '/' +  'eye_left' + every_image ), img_left)\n","            cv2.imwrite(os.path.join(validation_path, image_name + '/' +  'eye_right' + every_image), img_right)\n","        if count % 100 == 0:\n","            print(image_name + 'saved' + str(count) )   \n","        count += 1\n","\n","    return image_name + \"done\"\n","    \n","\n"],"id":"4d55cd69","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"15d359e2"},"source":["class_list = [\"up\", \"down\", \"left\", \"right\", \"upper_left\", \"upper_right\", \"lower_left\", \"lower_right\", \"middle\"]\n","#for every_class in class_list:\n","print(image_saver(class_list[8]))\n","    "],"id":"15d359e2","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7f7e3658"},"source":["exp_image = cv2.imread('dataset/images/experiment/IMG20210618175653.jpg')\n","img1, img2 = eye_crop(exp_image)\n","plt.imshow(img1)"],"id":"7f7e3658","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e13a239e-03af-4fb1-8c94-ceab539a7b7b"},"source":["hello_world()"],"id":"e13a239e-03af-4fb1-8c94-ceab539a7b7b","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"id":"f95df50d"},"source":["# Applying Mediapipe to single images and save outputs to inspect and decide which distances to use"],"id":"f95df50d"},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"tags":[],"id":"6c59b02e"},"source":["import cv2\n","import mediapipe as mp\n","import time\n","import os\n","\n","import pandas as pd\n","\n","\n","mpDraw = mp.solutions.drawing_utils\n","mpFaceMesh = mp.solutions.face_mesh\n","faceMesh = mpFaceMesh.FaceMesh(max_num_faces=2)\n","drawSpec = mpDraw.DrawingSpec(thickness=1, circle_radius=0)\n","\n","\n","\n","max_count = 10\n","mesh_image = 'facemesh'\n","\n","path = 'dataset/images/experiment'\n","path2 = 'dataset/images/experiment_output'\n","\n","\n","if not os.path.isdir(path2):\n","    os.mkdir(path2)\n","    \n","images = os.listdir(path)\n","\n","path_mesh = os.path.join(path2, mesh_image)\n","\n","for every_image in images:\n","    img = cv2.imread(path+'/' + every_image)\n","    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    results = faceMesh.process(imgRGB)\n","    if results.multi_face_landmarks:\n","        for faceLms in results.multi_face_landmarks:\n","            mpDraw.draw_landmarks(img, faceLms, None, \n","                                  drawSpec, drawSpec)\n","            for id, lm in enumerate(faceLms.landmark):\n","\n","                ih, iw, ic = img.shape\n","                x, y = int(lm.x*iw), int(lm.y*ih)\n","                cv2.putText(img, str(id), (x, y), cv2.FONT_HERSHEY_PLAIN,\n","                            0.5, (0, 255, 0), 1)\n","    cv2.imwrite(os.path.join(path2, mesh_image + str(every_image) +'.jpg'), img)"],"id":"6c59b02e","execution_count":null,"outputs":[]}]}